{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/Siraj-R-Khan/NeMo-Guardrails.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from chatbot import Chatbot\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = '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'\n",
    "\n",
    "bot = Chatbot(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = bot._call(\"what should I buy if I'd like to bake a cheesecake?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot._call(\"thanks, could you suggest some alternatives for the Graham cracker crumbs?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot._call(\"that's great, I'll try it with Oreo Cookies!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot._call(\"actually yes I have more questions, what can you tell me about the president of the USA?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot._call(\"yes, I'd love to know what people think of the president and how he has done in office?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot._call(\"can you give me a concrete example of one of these opinions, just a generic example?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot._call(\"what could an example of a negatiive view of this be?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot._call(\"why would someone view his approach to immigration to be ineffective?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot._call(\"should we be talking about politics, given you're a shopping assistant?\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Chatbot with Guardrails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rails_chatbot import Chatbot\n",
    "\n",
    "bot = Chatbot(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "async def main(query: str):\n",
    "    out = await bot._call(query)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content=\"what should I buy if I'd like to bake a cheesecake?\", additional_kwargs={}, example=False)]\n",
      "[{'role': 'human', 'content': \"what should I buy if I'd like to bake a cheesecake?\"}]\n",
      "len(chat_history) > 1\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m asyncio\u001b[39m.\u001b[39;49mrun(bot\u001b[39m.\u001b[39;49m_call(\u001b[39m\"\u001b[39;49m\u001b[39mwhat should I buy if I\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39md like to bake a cheesecake?\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/redacre/lib/python3.11/site-packages/nest_asyncio.py:35\u001b[0m, in \u001b[0;36m_patch_asyncio.<locals>.run\u001b[0;34m(main, debug)\u001b[0m\n\u001b[1;32m     33\u001b[0m task \u001b[39m=\u001b[39m asyncio\u001b[39m.\u001b[39mensure_future(main)\n\u001b[1;32m     34\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 35\u001b[0m     \u001b[39mreturn\u001b[39;00m loop\u001b[39m.\u001b[39;49mrun_until_complete(task)\n\u001b[1;32m     36\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     37\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m task\u001b[39m.\u001b[39mdone():\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/redacre/lib/python3.11/site-packages/nest_asyncio.py:90\u001b[0m, in \u001b[0;36m_patch_loop.<locals>.run_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m f\u001b[39m.\u001b[39mdone():\n\u001b[1;32m     88\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m     89\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mEvent loop stopped before Future completed.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 90\u001b[0m \u001b[39mreturn\u001b[39;00m f\u001b[39m.\u001b[39;49mresult()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/redacre/lib/python3.11/asyncio/futures.py:203\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__log_traceback \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 203\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\u001b[39m.\u001b[39mwith_traceback(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception_tb)\n\u001b[1;32m    204\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/redacre/lib/python3.11/asyncio/tasks.py:267\u001b[0m, in \u001b[0;36mTask.__step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    264\u001b[0m     \u001b[39mif\u001b[39;00m exc \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    265\u001b[0m         \u001b[39m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[1;32m    266\u001b[0m         \u001b[39m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m         result \u001b[39m=\u001b[39m coro\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    268\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    269\u001b[0m         result \u001b[39m=\u001b[39m coro\u001b[39m.\u001b[39mthrow(exc)\n",
      "File \u001b[0;32m~/Documents/projects/examples/learn/generation/chatbots/nemo-guardrails/00-intro/rails_chatbot.py:157\u001b[0m, in \u001b[0;36mChatbot._call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[39m# apply guardrails considering the chat history incl. most recent interactions\u001b[39;00m\n\u001b[1;32m    156\u001b[0m     coro \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mguardrails\u001b[39m.\u001b[39mapply_guardrails(chat_history)\n\u001b[0;32m--> 157\u001b[0m     res, intermediate_steps \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m coro\n\u001b[1;32m    158\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    159\u001b[0m     \u001b[39m# guardrails not enabled, so just process directly via agent\u001b[39;00m\n\u001b[1;32m    160\u001b[0m     res, intermediate_steps \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39magent({\u001b[39m'\u001b[39m\u001b[39minput\u001b[39m\u001b[39m'\u001b[39m: inputs})\n",
      "File \u001b[0;32m~/Documents/projects/examples/learn/generation/chatbots/nemo-guardrails/00-intro/rails_chatbot.py:93\u001b[0m, in \u001b[0;36mGuardrails.apply_guardrails\u001b[0;34m(self, chat_history)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mlen(chat_history) > 1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     92\u001b[0m \u001b[39m# apply guardrails considering the chat history incl. most recent interactions\u001b[39;00m\n\u001b[0;32m---> 93\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrails\u001b[39m.\u001b[39mgenerate_async(messages\u001b[39m=\u001b[39mchat_history)\n\u001b[1;32m     94\u001b[0m \u001b[39mprint\u001b[39m(response)\n\u001b[1;32m     95\u001b[0m response \u001b[39m=\u001b[39m response[\u001b[39m'\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/redacre/lib/python3.11/site-packages/nemoguardrails/rails/llm/llmrails.py:228\u001b[0m, in \u001b[0;36mLLMRails.generate_async\u001b[0;34m(self, prompt, messages)\u001b[0m\n\u001b[1;32m    225\u001b[0m events \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_events_for_messages(messages)\n\u001b[1;32m    227\u001b[0m \u001b[39m# Compute the new events.\u001b[39;00m\n\u001b[0;32m--> 228\u001b[0m new_events \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mruntime\u001b[39m.\u001b[39mgenerate_events(events)\n\u001b[1;32m    230\u001b[0m \u001b[39m# Extract and join all the messages from bot_said events as the response.\u001b[39;00m\n\u001b[1;32m    231\u001b[0m responses \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/redacre/lib/python3.11/site-packages/nemoguardrails/flows/runtime.py:148\u001b[0m, in \u001b[0;36mRuntime.generate_events\u001b[0;34m(self, events)\u001b[0m\n\u001b[1;32m    145\u001b[0m new_events \u001b[39m=\u001b[39m []\n\u001b[1;32m    147\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 148\u001b[0m     last_event \u001b[39m=\u001b[39m events[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m]\n\u001b[1;32m    150\u001b[0m     log\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mProcessing event: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, last_event)\n\u001b[1;32m    152\u001b[0m     event_type \u001b[39m=\u001b[39m last_event[\u001b[39m\"\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "asyncio.run(bot._call(\"what should I buy if I'd like to bake a cheesecake?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = bot._call(\"what should I buy if I'd like to bake a cheesecake?\")\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "redacre",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
